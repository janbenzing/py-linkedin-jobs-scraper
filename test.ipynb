{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from linkedin_jobs_scraper import LinkedinScraper\n",
    "from linkedin_jobs_scraper.events import Events, EventData, EventMetrics\n",
    "from linkedin_jobs_scraper.query import Query, QueryOptions, QueryFilters\n",
    "from linkedin_jobs_scraper.filters import RelevanceFilters, TimeFilters, TypeFilters, ExperienceLevelFilters, \\\n",
    "    OnSiteOrRemoteFilters, SalaryBaseFilters\n",
    "\n",
    "# Change root logger level (default is WARN)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# Fired once for each successfully processed job\n",
    "def on_data(data: EventData):\n",
    "    print('[ON_DATA]', data.title, data.company, data.company_link, data.date, data.link, data.insights,\n",
    "          len(data.description))\n",
    "\n",
    "\n",
    "# Fired once for each page (25 jobs)\n",
    "def on_metrics(metrics: EventMetrics):\n",
    "    print('[ON_METRICS]', str(metrics))\n",
    "\n",
    "\n",
    "def on_error(error):\n",
    "    print('[ON_ERROR]', error)\n",
    "\n",
    "\n",
    "def on_end():\n",
    "    print('[ON_END]')\n",
    "\n",
    "\n",
    "scraper = LinkedinScraper(\n",
    "    chrome_executable_path=None,  # Custom Chrome executable path (e.g. /foo/bar/bin/chromedriver)\n",
    "    chrome_binary_location=None,  # Custom path to Chrome/Chromium binary (e.g. /foo/bar/chrome-mac/Chromium.app/Contents/MacOS/Chromium)\n",
    "    chrome_options=None,  # Custom Chrome options here\n",
    "    headless=True,  # Overrides headless mode only if chrome_options is None\n",
    "    max_workers=1,  # How many threads will be spawned to run queries concurrently (one Chrome driver for each thread)\n",
    "    slow_mo=0.5,  # Slow down the scraper to avoid 'Too many requests 429' errors (in seconds)\n",
    "    page_load_timeout=40  # Page load timeout (in seconds)    \n",
    ")\n",
    "\n",
    "# Add event listeners\n",
    "scraper.on(Events.DATA, on_data)\n",
    "scraper.on(Events.ERROR, on_error)\n",
    "scraper.on(Events.END, on_end)\n",
    "\n",
    "queries = [\n",
    "    Query(\n",
    "        options=QueryOptions(\n",
    "            limit=27  # Limit the number of jobs to scrape.            \n",
    "        )\n",
    "    ),\n",
    "    Query(\n",
    "        query='Engineer',\n",
    "        options=QueryOptions(\n",
    "            locations=['United States', 'Europe'],\n",
    "            apply_link=True,  # Try to extract apply link (easy applies are skipped). If set to True, scraping is slower because an additional page must be navigated. Default to False.\n",
    "            skip_promoted_jobs=True,  # Skip promoted jobs. Default to False.\n",
    "            page_offset=2,  # How many pages to skip\n",
    "            limit=5,\n",
    "            filters=QueryFilters(\n",
    "                company_jobs_url='https://www.linkedin.com/jobs/search/?f_C=1441%2C17876832%2C791962%2C2374003%2C18950635%2C16140%2C10440912&geoId=92000000',  # Filter by companies.                \n",
    "                relevance=RelevanceFilters.RECENT,\n",
    "                time=TimeFilters.MONTH,\n",
    "                type=[TypeFilters.FULL_TIME, TypeFilters.INTERNSHIP],\n",
    "                on_site_or_remote=[OnSiteOrRemoteFilters.REMOTE],\n",
    "                experience=[ExperienceLevelFilters.MID_SENIOR],\n",
    "                base_salary=SalaryBaseFilters.SALARY_100K\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "scraper.run(queries)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
